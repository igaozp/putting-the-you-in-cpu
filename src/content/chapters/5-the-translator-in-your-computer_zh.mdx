---
chapter: 5
title: 你计算机中的翻译器
shortname: 分页
slug: the-translator-in-your-computer
updatedAt: 2023-08-15T18:49:01.686Z
---

import CodeBlock from '../../components/CodeBlock.astro'

到目前为止，每次我谈到读写内存时都有点含糊其辞。例如，ELF 文件指定要将数据加载到的特定内存地址，那么为什么不同进程尝试使用冲突的内存没有问题？为什么每个进程似乎都有不同的内存环境？

此外，我们究竟是如何到达这里的？我们理解 `execve` 是一个用新程序*替换*当前进程的系统调用，但这并不能解释如何启动多个进程。它绝对不能解释第一个程序是如何运行的——是什么鸡（进程）下（生成）所有其他蛋（其他进程）？

我们正接近旅程的终点。在回答了这两个问题之后，我们将对你的计算机如何从启动到运行你现在正在使用的软件有一个基本完整的理解。

## 内存是假的

所以……关于内存。事实证明，当 CPU 读取或写入内存地址时，它实际上并不是指*物理*内存（RAM）中的那个位置。相反，它指向*虚拟*内存空间中的位置。

CPU 与一个称为[*内存管理单元*](https://en.wikipedia.org/wiki/Memory_management_unit)（MMU）的芯片对话。MMU 就像一个带有字典的翻译器，将虚拟内存中的位置翻译成 RAM 中的位置。当 CPU 被指示从内存地址 `0xfffaf54834067fe2` 读取时，它要求 MMU 翻译该地址。MMU 在字典中查找它，发现匹配的物理地址是 `0x53a4b64a90179fe2`，并将数字发送回 CPU。然后，CPU 可以从 RAM 中的该地址读取。

<img src='/images/virtual-memory-mmu-example.png' loading='eager' style='max-width: 640px; margin: 0 auto;' alt='一幅微笑的 CPU 和 MMU 进行对话的图画。MMU 是一个高大的芯片，戴着图书馆眼镜，手里拿着一本标记为"字典：指针 0x0000 到 0xffff"的大书。CPU 要求 MMU 翻译一个长内存地址。MMU 思考了一秒钟，并用不同的指针回应。' width='1207' height='454' />

当计算机首次启动时，内存访问直接进入物理 RAM。启动后立即，操作系统创建翻译字典并告诉 CPU 开始使用 MMU。

这个字典实际上被称为*页表*，这个翻译每个内存访问的系统被称为*分页*。页表中的条目称为*页*，每个条目表示虚拟内存的某个块如何映射到 RAM。这些块总是固定大小的，每个处理器架构都有不同的页大小。x86-64 具有默认的 4 KiB 页大小，这意味着每个页指定 4,096 字节长的内存块的映射。

换句话说，使用 4 KiB 页，地址的底部 12 位在 MMU 翻译之前和之后总是相同的——12，因为这是索引翻译后获得的 4,096 字节页所需的位数。

x86-64 还允许操作系统启用更大的 2 MiB 或 4 GiB 页，这可以提高地址翻译速度，但会增加内存碎片和浪费。页大小越大，由 MMU 翻译的地址部分越小。

<img src='/images/4kib-paging-address-breakdown.png' loading='lazy' style='max-width: 400px; margin: 0 auto;' alt='使用 4 KiB 分页的内存地址分解。最低 12 位索引页，其余位由 MMU 翻译并成为页的起始地址。' width='760' height='310' />

页表本身只驻留在 RAM 中。虽然它可以包含数百万个条目，但每个条目的大小只有几个字节的数量级，因此页表不会占用太多空间。

要在启动时启用分页，内核首先在 RAM 中构造页表。然后，它将页表开始的物理地址存储在称为页表基址寄存器（PTBR）的寄存器中。最后，内核启用分页以使用 MMU 翻译所有内存访问。在 x86-64 上，控制寄存器 3（CR3）的顶部 20 位充当 PTBR。CR0 的第 31 位，指定为 PG（分页），设置为 1 以启用分页。

分页系统的魔力在于页表可以在计算机运行时编辑。这就是每个进程如何拥有自己的隔离内存空间——当操作系统从一个进程切换到另一个进程时，一个重要的任务是将虚拟内存空间重新映射到物理内存中的不同区域。假设你有两个进程：进程 A 可以在 `0x0000000000400000` 处拥有其代码和数据（可能从 ELF 文件加载！），进程 B 可以从完全相同的地址访问其代码和数据。这两个进程甚至可以是同一程序的实例，因为它们实际上并没有争夺该地址范围！进程 A 的数据在物理内存中远离进程 B 的某个地方，并在切换到进程时由内核映射到 `0x0000000000400000`。

<img src='/images/process-virtual-memory-mapping.png' loading='lazy' alt='一个图表显示两个不同的进程要求一个拟人化桌面计算机的俗气剪贴画图像翻译相同的内存地址。拟人化计算机用物理内存连续条中的不同部分回应每个进程。' width='2101' height='1010' />

> **补充说明：诅咒的 ELF 事实**
>
> 在某些情况下，`binfmt_elf` 必须将内存的第一页映射为零。一些为 UNIX System V Release 4.0（SVr4）编写的程序（这是 1988 年第一个支持 ELF 的操作系统）依赖于可读的空指针。不知何故，一些程序仍然依赖于这种行为。
>
> 实现这一点的 Linux 内核开发人员似乎[有点不满](https://github.com/torvalds/linux/blob/22b8cc3e78f5448b4c5df00303817a9137cd663f/fs/binfmt_elf.c#L1322-L1329)：
>
> *"你问为什么这样做？好吧，SVr4 将第 0 页映射为只读，一些应用程序'依赖'这种行为。由于我们没有权力重新编译这些，我们模拟 SVr4 行为。叹气。"*
>
> 叹气。

## 分页的安全性

由内存分页启用的进程隔离改善了代码的人体工程学（进程不需要知道其他进程就可以使用内存），但它也创建了一个安全级别：进程无法访问其他进程的内存。这部分回答了本文开头的原始问题之一：

> 如果程序直接在 CPU 上运行，并且 CPU 可以直接访问 RAM，为什么代码不能访问其他进程的内存，或者，天哪，内核的内存？

*还记得吗？感觉像是很久以前的事了……*

那内核内存呢？首先：内核显然需要存储大量自己的数据，以跟踪所有正在运行的进程，甚至页表本身。每次触发硬件中断、软件中断或系统调用并且 CPU 进入内核模式时，内核代码需要以某种方式访问该内存。

Linux 的解决方案是始终将虚拟内存空间的上半部分分配给内核，因此 Linux 被称为[*高半核*](https://wiki.osdev.org/Higher_Half_Kernel)。Windows 采用[类似](https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/overview-of-windows-memory-space)的技术，而 macOS 则……[稍微](https://www.researchgate.net/figure/Overview-of-the-Mac-OS-X-virtual-memory-system-which-resides-inside-the-Mach-portion-of_fig1_264086271)[更](https://developer.apple.com/library/archive/documentation/Performance/Conceptual/ManagingMemory/Articles/AboutMemory.html)[复杂](https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/vm/vm.html)，阅读它让我的大脑从耳朵里流出。\~(++)\~

<img src='/images/higher-half-kernel-memory-map.png' loading='lazy' alt='一个将虚拟内存空间显示为条带的图表。左半部分标记为用户空间：执行程序的内存。右半部分标记为内核空间：与内核相关的所有内容的固定区域。分隔两段的中点标记为内存地址 0x8000000000000000。' width='2161' height='230' />

然而，如果用户空间进程可以读取或写入内核内存，对安全性来说将是可怕的，因此分页启用了第二层安全性：每个页必须指定权限标志。一个标志确定区域是可写还是只读。另一个标志告诉 CPU 只有内核模式才被允许访问该区域的内存。后一个标志用于保护整个高半核空间——整个内核内存空间实际上在用户空间程序的虚拟内存映射中可用，它们只是没有访问它的权限。

<img src='/images/page-table-entry-permissions.png' loading='lazy' style='max-width: 260px;' alt='页表条目权限表。存在：真。读/写：只读。用户/内核：所有模式。脏：假。访问：真。等等。' width='650' height='639' />

页表本身实际上包含在内核内存空间中！当计时器芯片触发进程切换的硬件中断时，CPU 将特权级别切换到内核模式并跳转到 Linux 内核代码。处于内核模式（Intel 环 0）允许 CPU 访问内核保护的内存区域。然后，内核可以写入页表（驻留在内存上半部分的某个地方）以重新映射新进程的虚拟内存的下半部分。当内核切换到新进程并且 CPU 进入用户模式时，它不再能够访问任何内核内存。

几乎每个内存访问都通过 MMU。中断描述符表处理程序指针？这些也寻址内核的虚拟内存空间。

## 分层分页和其他优化

64 位系统具有 64 位长的内存地址，这意味着 64 位虚拟内存空间的大小高达 16 [艾字节](https://en.wiktionary.org/wiki/exbibyte)。这非常大，远大于今天或不久的将来存在的任何计算机。据我所知，有史以来任何计算机中的最大 RAM 是在 [Blue Waters 超级计算机](https://en.wikipedia.org/wiki/Blue_Waters)中，拥有超过 1.5 拍字节的 RAM。这仍然不到 16 EiB 的 0.01%。

如果虚拟内存空间的每个 4 KiB 部分都需要页表中的一个条目，你将需要 4,503,599,627,370,496 个页表条目。使用 8 字节长的页表条目，你将需要 32 拍字节的 RAM 仅用于存储页表本身。你可能会注意到这仍然大于计算机中最大 RAM 的世界纪录。

> **补充说明：为什么是奇怪的单位？**
>
> 我知道这不常见，而且真的很丑，但我认为清楚地区分二进制字节大小单位（2 的幂）和公制单位（10 的幂）很重要。千字节，kB，是一个 SI 单位，意思是 1,000 字节。千二字节，KiB，是一个 IEC 推荐的单位，意思是 1,024 字节。在 CPU 和内存地址方面，字节计数通常是 2 的幂，因为计算机是二进制系统。使用 KB（或更糟糕的是 kB）表示 1,024 会更加模糊。

由于为整个可能的虚拟内存空间拥有顺序页表条目是不可能的（或至少非常不切实际），CPU 架构实现了*分层分页*。在分层分页系统中，有多个级别的页表，粒度越来越小。顶级条目覆盖大块内存并指向较小块的页表，创建树结构。4 KiB 或任何页大小的块的各个条目是树的叶子。

x86-64 历史上使用 4 级分层分页。在此系统中，通过使用地址的一部分偏移包含表的开始来找到每个页表条目。这部分从最高有效位开始，它们作为前缀工作，因此条目覆盖以这些位开头的所有地址。条目指向下一级表的开始，包含该内存块的子树，它们再次用下一组位索引。

x86-64 的 4 级分页的设计者还选择忽略所有虚拟指针的顶部 16 位以节省页表空间。48 位给你 128 TiB 的虚拟地址空间，这被认为足够大。（完整的 64 位将为你提供 16 EiB，这有点多。）

由于跳过了前 16 位，索引页表第一级的"最高有效位"实际上从第 47 位开始，而不是第 63 位。这也意味着本章前面的高半核图表在技术上是不准确的；内核空间起始地址应该被描绘为小于 64 位的地址空间的中点。

<img src='/images/multilevel-paging-explainer.png' loading='lazy' class='big' alt='一个大型、详细和全彩色的 x86-64 上 4 级分页图表。它描绘了四个级别的页表，突出显示在每个级别充当"前缀"的位。它还显示通过将位的值添加到表的基址来通过这些前缀位索引表。每个表中的条目指向下一个表的开始，除了最终级别 1，它指向 RAM 中 4 KiB 块的开始。MMU 将最低 12 位添加到该地址以获得最终物理地址。有一个级别 4 表，n 平方级别 3 表，依此类推。' width='2981' height='1118' />

分层分页解决了空间问题，因为在树的任何级别，指向下一个条目的指针可以为空（`0x0`）。这允许省略页表的整个子树，这意味着虚拟内存空间的未映射区域不会占用 RAM 中的任何空间。未映射内存地址的查找可以快速失败，因为 CPU 可以在看到树中较高位置的空条目时立即出错。页表条目还有一个存在标志，即使地址看起来有效，也可以用来标记它们为不可用。

分层分页的另一个好处是能够有效地切换虚拟内存空间的大块。大量虚拟内存可能映射到一个进程的物理内存的一个区域，而对于另一个进程则是不同的区域。内核可以将两个映射存储在内存中，并在切换进程时简单地更新树顶层的指针。如果整个内存空间映射存储为条目的扁平数组，内核将不得不更新许多条目，这会很慢，并且仍然需要独立跟踪每个进程的内存映射。

我说 x86-64"历史上"使用 4 级分页，因为最近的处理器实现了 [5 级分页](https://en.wikipedia.org/wiki/Intel_5-level_paging)。5 级分页增加了另一个间接级别以及 9 个更多的寻址位，以使用 57 位地址将地址空间扩展到 128 PiB。5 级分页自 [2017 年](https://lwn.net/Articles/717293/)以来由包括 Linux 在内的操作系统以及最近的 Windows 10 和 11 服务器版本支持。

> **补充说明：物理地址空间限制**
>
> 正如操作系统不使用所有 64 位用于虚拟地址一样，处理器也不使用整个 64 位物理地址。当 4 级分页是标准时，x86-64 CPU 不使用超过 46 位，这意味着物理地址空间仅限于 64 TiB。使用 5 级分页，支持已扩展到 52 位，支持 4 PiB 物理地址空间。
>
> 在操作系统级别，虚拟地址空间大于物理地址空间是有利的。正如 Linus Torvalds [所说](https://www.realworldtech.com/forum/?threadid=76912&curpostid=76973)，"[它]需要更大，至少是两倍的因子，坦率地说这是在推它，你最好有十倍或更多的因子。任何不理解这一点的人都是白痴。讨论结束。"

## 交换和按需分页

内存访问可能由于几个原因而失败：地址可能超出范围，它可能未被页表映射，或者它可能有一个标记为不存在的条目。在任何这些情况下，MMU 将触发一个称为*页错误*的硬件中断，让内核处理问题。

在某些情况下，读取确实无效或被禁止。在这些情况下，内核可能会以[段错误](https://en.wikipedia.org/wiki/Segmentation_fault)错误终止程序。

<CodeBlock name='Shell session'>
```
$ ./program
Segmentation fault (core dumped)
$
```
</CodeBlock>

> **补充说明：段错误本体论**
>
> "段错误"在不同的上下文中意味着不同的东西。当未经许可读取内存时，MMU 会触发一个称为"段错误"的硬件中断，但"段错误"也是操作系统可以发送给正在运行的程序的信号的名称，以便由于任何非法内存访问而终止它们。

在其他情况下，内存访问可以*故意*失败，允许操作系统填充内存，然后*将控制权交还给 CPU 以重试*。例如，操作系统可以将磁盘上的文件映射到虚拟内存，而实际上并不将其加载到 RAM 中，然后在请求地址并发生页错误时将其加载到物理内存中。这称为*按需分页*。

<img src='/images/demand-paging-with-page-faults-comic.png' loading='lazy' class='big' alt='一个关于如何使用硬件中断实现按需分页的三面板漫画风格图表。面板 1：CPU 与 MMU 进行对话。CPU 说"读取 0xfff"，MMU 看起来很困惑，然后 MMU 向 CPU 发送标记为"页错误！"的闪电。面板 2 标记为"页错误处理程序"，并具有锯齿轮廓。它描绘了 CPU 将一些数据加载到 RAM 中，然后从中断返回。最后，面板 3 回到 CPU 和 MMU 对话。MMU 对自己想，"哦嘿，页现在存在了。"它回复 CPU 的原始请求："这是你的内存！"CPU 说谢谢。' width='3001' height='703' style='--max-width: 1000px;' />

首先，这允许像 [mmap](https://man7.org/linux/man-pages/man2/mmap.2.html) 这样的系统调用延迟将整个文件从磁盘映射到虚拟内存中存在。如果你熟悉 LLaMa.cpp，一个泄漏的 Facebook 语言模型的运行时，Justine Tunney 最近通过[使所有加载逻辑使用 mmap](https://justine.lol/mmap/) 显著优化了它。（如果你以前没有听说过她，[看看她的东西](https://justine.lol/)！Cosmopolitan Libc 和 APE 真的很酷，如果你一直在享受这篇文章，可能会很有趣。）

> *显然，关于 Justine 参与此更改有[很多](https://rentry.org/Jarted)[戏剧](https://news.ycombinator.com/item?id=35413289)[性](https://news.ycombinator.com/item?id=35458004)。只是指出这一点，这样我就不会被随机的互联网用户尖叫。我必须承认，我还没有阅读大部分戏剧，我说的关于 Justine 的东西很酷的一切仍然非常真实。*

当你执行一个程序及其库时，内核实际上并不将任何东西加载到内存中。它只创建文件的 mmap——当 CPU 尝试执行代码时，页立即出错，内核用真实的内存块替换页。

按需分页还启用了你可能在"交换"或"分页"名称下看到的技术。操作系统可以通过将内存页写入磁盘来释放物理内存，然后从物理内存中删除它们，但将它们保留在虚拟内存中，存在标志设置为 0。如果读取该虚拟内存，操作系统可以从磁盘恢复内存到 RAM 并将存在标志设置回 1。操作系统可能不得不交换不同的 RAM 部分，以为从磁盘加载的内存腾出空间。磁盘读写很慢，因此操作系统尝试使用[高效的页面替换算法](https://en.wikipedia.org/wiki/Page_replacement_algorithm)使交换尽可能少地发生。

一个有趣的技巧是使用页表物理内存指针来存储物理存储中文件的位置。由于 MMU 会在看到负存在标志时立即页错误，它们是无效内存地址并不重要。这在所有情况下都不实用，但想想很有趣。
